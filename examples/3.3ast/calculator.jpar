%option LALR

%{
abstract type Operand end
add(a::Operand, b::Operand)::Operand = a + b
sub(a::Operand, b::Operand)::Operand = a - b
mul(a::Operand, b::Operand)::Operand = a * b
div(a::Operand, b::Operand)::Operand = a / b

struct GF{P} <: Operand
  value::Int
  GF{P}(value::Int) where {P} = new(mod(value, P))
end
(Base.:+)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value + b.value)
(Base.:-)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value - b.value)
(Base.:*)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value * b.value)
(Base.:/)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value * invmod(b.value, P))
Base.show(io::IO, a::GF{P}) where P = print(io, "GaloisField{order=$P}($(a.value))")

FIELD_PRIME::Int = 7
%}
%{
abstract type Node end

struct Num <: Node
  value::Operand
end

struct AddExpr <: Node
  left::Node
  right::Node
end

struct SubExpr <: Node
  left::Node
  right::Node
end

struct MulExpr <: Node
  left::Node
  right::Node
end

struct DivExpr <: Node
  left::Node
  right::Node
end

eval(n::Num)::Operand     = n.value
eval(n::AddExpr)::Operand = add(eval(n.left), eval(n.right))
eval(n::SubExpr)::Operand = sub(eval(n.left), eval(n.right))
eval(n::MulExpr)::Operand = mul(eval(n.left), eval(n.right))
eval(n::DivExpr)::Operand = div(eval(n.left), eval(n.right))
%}

#= Lexer token definitions =#
%token MULTIPLY "*"
%token DIVIDE "/"
%token ADD "+"
%token SUBTRACT "-"
%token LPAREN "("
%token RPAREN ")"
%token NUMBER

#= Returned types =#
%type <Node> e
%type <Node> t
%type <Node> f

%%
#= Productions =#
%start s
s -> e         :{ println($1); println(eval($1))      }:
e -> e "+" t   :{ $$ = AddExpr($1, $3)                }:
   | e "-" t   :{ $$ = SubExpr($1, $3)                }:
   | t         :{ $$ = $1                             }:
t -> t "*" f   :{ $$ = MulExpr($1, $3)                }:
   | t "/" f   :{ $$ = DivExpr($1, $3)                }:
   | f         :{ $$ = $1                             }:
f -> NUMBER    :{ $$ = Num(GF{FIELD_PRIME}($1.value)) }:
   | "(" e ")" :{ $$ = $2                             }:

%%

function __PAR__usage()
  println("Usage: $(PROGRAM_FILE) [source file] [order]")
end

function __PAR__main()
  if length(ARGS) != 2
    return __PAR__usage()
  elseif ARGS[1] == "-h" || ARGS[1] == "--help"
    return __PAR__usage()
  elseif !isfile(ARGS[1])
    error("File \"$(ARGS[1])\" does not exist")
  else
    try
      global FIELD_PRIME = parse(Int, ARGS[2])
    catch e
      error("Invalid order argument, must be an integer, got: \"$(ARGS[2])\"")
    end

    txt = ""
    open(ARGS[1]) do file
      txt = read(file, String)
      __LEX__bind_cursor(Cursor(txt; source=ARGS[1]))
    end

    tokens = nothing
    try
      tokens = __LEX__tokenize()
    catch e
      e = ErrorException(replace(e.msg, r"\n       " => "\n"))
      @error "Error while tokenizing input" exception=(e, catch_backtrace())
      exit(1)
    end

    try
      __PAR__simulate(tokens)
    catch e
      if e isa ErrorException
        e = ErrorException(replace(e.msg, r"\n       " => "\n"))
        @error "Error while parsing tokens" exception=(e, catch_backtrace())
        exit(1)
      end
      @error "Error while parsing tokens" exception=(e, catch_backtrace())
    end
  end

  return __PAR__at_end()
end
