var documenterSearchIndex = {"docs":
[{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/#Generating-a-lexer","page":"Usage","title":"Generating a lexer","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"After the lexer definition file is created, it can be used to generate a lexer. To do so, run the following program:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using JLRPG\ngenerate_lexer(\"path/to/lexer.jlex\", \"path/to/generated/lexer.jl\")","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"This will generate a lexer file in the specified location. The generated lexer file will contain all the variables needed to tokenize the input string. Running the lexer directly without an input file path will open an stdin prompt, which has to be terminated with Ctrl+D combination. To run the lexer on a file, pass the file path as the first command line argument.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"To see the actions performed by the lexer, run it with the JULIA_DEBUG=Main environment variable set:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"JULIA_DEBUG=Main julia path/to/generated/lexer.jl [source file]","category":"page"},{"location":"usage/#Generating-a-parser","page":"Usage","title":"Generating a parser","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"To generate a parser, run the following program:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using JLRPG\ngenerate_parser(\"path/to/parser.jpar\", \"path/to/generated/parser.jl\")","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"This will generate a parser file in the specified location. The generated parser file will contain all the variables needed to parse the input string. To run the parser on a file, pass the file path as the first command line argument.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Generated parsers require a path to the lexer file to be specified in the parses definition file. By default the generated parser program checks, whether a __LEX__.jl file is present in the same directory as the parser file. If it is not, a warning message is printed. To specify a custom lexer file path, include it inside of a code section/block in the parser definition file:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"%{\ninclude(\"path/to/lexer.jl\")\n%}","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"To see the actions performed by the parser, run it with the JULIA_DEBUG=Main environment variable set:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"JULIA_DEBUG=Main julia path/to/generated/parser.jl [source file]","category":"page"},{"location":"api_parser/#Parser-API-reference","page":"Parser","title":"Parser API reference","text":"","category":"section"},{"location":"api_parser/","page":"Parser","title":"Parser","text":"Modules = [JLRPG.JLRPG_Parser]\nOrder   = [:type, :function]","category":"page"},{"location":"api_parser/#JLRPG.JLRPG_Parser.Parser","page":"Parser","title":"JLRPG.JLRPG_Parser.Parser","text":"Parser definition.\n\nCreated by read_parser_definition_file function.\n\n\n\n\n\n","category":"type"},{"location":"api_parser/#JLRPG.JLRPG_Parser.ParserOptions","page":"Parser","title":"JLRPG.JLRPG_Parser.ParserOptions","text":"Parser options definition.\n\nCurrently only tag, parser_tag and parser_type options are supported. Option tag defines a tag that will be preprended to all objects generated in the parser file. Option lexer_tag defines a tag that will be preprended to all objects generated associated with the lexer in the parser file. Option parser_type defines the type of the parser to be generated (SLR, LALR or LR).\n\n\n\n\n\n","category":"type"},{"location":"api_parser/#JLRPG.JLRPG_Parser.ParserProduction","page":"Parser","title":"JLRPG.JLRPG_Parser.ParserProduction","text":"Parser production definition.\n\nA parser production is a rule of the form:\n\nA -> B1 B2 ... Bn\n\n# or if the production is an alternative to previous production\nA -> B1 B2 ... Bn\n   | C1 C2 ... Cm\n\nwhere A is a nonterminal and B1, B2, ..., Bn (C1, C2, ..., Cn) is a string of grammar symbols (terminals or nonterminals).\n\nThe action is an optional string of Julia code that is executed when the production is reduced. The action can be used to build an AST or to execute arbitrary code.\n\nThe return type is the type of the value returned by the action. If the action is not defined, the return type is nothing.\n\n\n\n\n\n","category":"type"},{"location":"api_parser/#JLRPG.JLRPG_Parser.ParsingItem","page":"Parser","title":"JLRPG.JLRPG_Parser.ParsingItem","text":"Parsing item definition.\n\nUsed for the construction of the parsing table.\n\n\n\n\n\n","category":"type"},{"location":"api_parser/#JLRPG.JLRPG_Parser.ParsingTable","page":"Parser","title":"JLRPG.JLRPG_Parser.ParsingTable","text":"Parsing table definition.\n\nThe parsing table is used by the parser to decide what action to take when it is in a certain state and reads a certain symbol.\n\nAll parsing table types have the same structure, but they differ in its content.\n\n\n\n\n\n","category":"type"},{"location":"api_parser/#JLRPG.JLRPG_Parser.ParsingTableAction","page":"Parser","title":"JLRPG.JLRPG_Parser.ParsingTableAction","text":"Parsing table action definition.\n\nThere are three types of actions:\n\nShift\nReduce\nAccept\n\nThe action is executed when the parser is in a certain state and reads a certain symbol.\n\n\n\n\n\n","category":"type"},{"location":"api_parser/#JLRPG.JLRPG_Parser.LalrParsingTable-Tuple{Parser}","page":"Parser","title":"JLRPG.JLRPG_Parser.LalrParsingTable","text":"LalrParsingTable(augmented_parser::Parser)\n\nGenerate the LALR parsing table for the augmented parser.\n\nThe augmented parser is the parser with the augmented start production.\n\nThis algorithm computes the LR(1) item sets and gotos, then merges the item sets that are equal. Finally, it generates the parsing table from the merged item sets and gotos (and mappings).\n\nThis algorithm is almost the same as the one used for the LR(1) parsing table. The procedure of generating the LR(1) table is described in the Dragon Book, sections 4.7.2, 4.7.3. The idea of merging the item sets is described in the section 4.7.4.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.LrParsingTable-Tuple{Parser}","page":"Parser","title":"JLRPG.JLRPG_Parser.LrParsingTable","text":"LrParsingTable(\n  augmented_parser::Parser\n)::ParsingTable\n\nCompute the LR(1) parsing table for a given parser.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.7.3.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.SlrParsingTable-Tuple{Parser}","page":"Parser","title":"JLRPG.JLRPG_Parser.SlrParsingTable","text":"SlrParsingTable(augmented_parser::Parser)\n\nGenerate the SLR parsing table for the augmented parser.\n\nThe augmented parser is the parser with the augmented start production.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.6.4.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.augment_parser-Tuple{Parser}","page":"Parser","title":"JLRPG.JLRPG_Parser.augment_parser","text":"augment_parser(parser::Parser)::Parser\n\nAugment the parser with the augmented start production.\n\nAdd the %start nonterminal to the set of nonterminals and the augmented start production to the set of productions.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.augment_productions-Tuple{Symbol, Symbol, Dict{Symbol, Vector{ParserProduction}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.augment_productions","text":"augment_productions(\n  starting::Symbol,\n  starting_return_type::Symbol,\n  productions::Dict{Symbol, Vector{ParserProduction}}\n)::Dict{Symbol, Vector{ParserProduction}}\n\nAdd the augmented start production to the set of productions.\n\nThe augmented start production is of the form:\n\n%start -> starting\n\nwhere starting is the starting nonterminal of the parser.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.fill_parser_template-Tuple{Vector{String}, ParsingTable, Dict{Symbol, Vector{ParserProduction}}, Dict{Symbol, Symbol}}","page":"Parser","title":"JLRPG.JLRPG_Parser.fill_parser_template","text":"fill_parser_template(\n  codeblocks::Vector{String},\n  table::ParsingTable,\n  productions::Dict{Symbol, Vector{ParserProduction}},\n  symbol_types::Dict{Symbol, Symbol}\n)::String\n\nFill the lexer mustache template with the data.\n\nThis function is used internally by generate_parser function.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.first_set_for_string_of_symbols-Tuple{Vector{Symbol}, Dict{Symbol, Set{Symbol}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.first_set_for_string_of_symbols","text":"first_set_for_string_of_symbols(\n  symbols::Vector{Symbol},\n  firsts::Dict{Symbol, Set{Symbol}}\n)::Set{Symbol}\n\nDetermine the first set for a string of symbols using precomputed first sets.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.first_sets-Tuple{Vector{Symbol}, Vector{Symbol}, Dict{Symbol, Vector{ParserProduction}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.first_sets","text":"first_sets(\n  terminals::Vector{Symbol},\n  nonterminals::Vector{Symbol},\n  productions::Dict{Symbol, Vector{ParserProduction}}\n)::Dict{Symbol, Set{Symbol}}\n\nCompute the first sets for the given grammar.\n\nThe first sets are computed using the algorithm provided in the Dragon Book, 2nd edition, pages 220-221.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.follow_sets-Tuple{Dict{Symbol, Set{Symbol}}, Vector{Symbol}, Vector{Symbol}, Dict{Symbol, Vector{ParserProduction}}, Symbol}","page":"Parser","title":"JLRPG.JLRPG_Parser.follow_sets","text":"follow_sets(\n  firsts::Dict{Symbol, Set{Symbol}},\n  terminals::Vector{Symbol},\n  nonterminals::Vector{Symbol},\n  productions::Dict{Symbol, Vector{ParserProduction}},\n  starting::Symbol\n)::Dict{Symbol, Set{Symbol}}\n\nCompute the follow sets for the given grammar.\n\nThe follow sets are computed using the algorithm provided in the Dragon Book, 2nd edition, pages 221-222.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.generate_parser","page":"Parser","title":"JLRPG.JLRPG_Parser.generate_parser","text":"generate_parser(definition_path::String, output_path::String=\"__PAR__.jl\")\n\nGenerate a parser source file from a parser definition file.\n\nThe parser definition file should follow the syntax described in both read_parser_definition_file and Parser module documentation.\n\n\n\n\n\n","category":"function"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr0_closure-Tuple{Vector{ParsingItem}, Dict{Symbol, Vector{ParserProduction}}, Vector{Symbol}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr0_closure","text":"lr0_closure(\n  items::Vector{ParsingItem},\n  productions::Dict{Symbol, Vector{ParserProduction}},\n  nonterminals::Vector{Symbol}\n)::Vector{ParsingItem}\n\nCompute the LR(0) closure of a set of items.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.6.2.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr0_goto-Tuple{Vector{ParsingItem}, Symbol, Dict{Symbol, Vector{ParserProduction}}, Vector{Symbol}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr0_goto","text":"lr0_goto(\n  items::Vector{ParsingItem},\n  symbol::Symbol,\n  productions::Dict{Symbol, Vector{ParserProduction}},\n  nonterminals::Vector{Symbol}\n)::Vector{ParsingItem}\n\nCompute the LR(0) goto of a set of items.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.6.2.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr0_items-Tuple{Dict{Symbol, Vector{ParserProduction}}, Vector{Symbol}, Vector{Symbol}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr0_items","text":"lr0_items(\n  augmented_productions::Dict{Symbol, Vector{ParserProduction}},\n  nonterminals::Vector{Symbol},\n  grammar_symbols::Vector{Symbol}\n)::Tuple{Vector{Vector{ParsingItem}}, Dict{Int, Dict{Symbol, Int}}}\n\nCompute the LR(0) items for the given grammar.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.6.2.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr1_closure-Tuple{Vector{ParsingItem}, Dict{Symbol, Vector{ParserProduction}}, Vector{Symbol}, Dict{Symbol, Set{Symbol}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr1_closure","text":"lr1_closure(\n  items::Vector{ParsingItem},\n  productions::Dict{Symbol, Vector{ParserProduction}},\n  nonterminals::Vector{Symbol},\n  firsts::Dict{Symbol, Set{Symbol}},\n)::Vector{ParsingItem}\n\nCompute the LR(1) closure of a set of items.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.7.2.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr1_goto-Tuple{Vector{ParsingItem}, Symbol, Dict{Symbol, Vector{ParserProduction}}, Vector{Symbol}, Dict{Symbol, Set{Symbol}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr1_goto","text":"lr1_goto(\n  items::Vector{ParsingItem},\n  symbol::Symbol,\n  productions::Dict{Symbol, Vector{ParserProduction}},\n  nonterminals::Vector{Symbol},\n  firsts::Dict{Symbol, Set{Symbol}},\n)::Vector{ParsingItem}\n\nCompute the LR(1) goto of a set of items.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.7.2.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr1_items-Tuple{Dict{Symbol, Vector{ParserProduction}}, Vector{Symbol}, Vector{Symbol}, Dict{Symbol, Set{Symbol}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr1_items","text":"lr1_items(\n  augmented_productions::Dict{Symbol, Vector{ParserProduction}},\n  nonterminals::Vector{Symbol},\n  grammar_symbols::Vector{Symbol},\n  firsts::Dict{Symbol, Set{Symbol}}\n)::Tuple{Vector{Vector{ParsingItem}}, Dict{Int, Dict{Symbol, Int}}}\n\nCompute the LR(1) items and gotos for a given grammar.\n\nThe procedure is described in the Dragon Book, 2nd edition, section 4.7.2.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.lr1_kernels-Tuple{Vector{Vector{ParsingItem}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.lr1_kernels","text":"lr1_kernels(lr1_item_sets::Vector{Vector{ParsingItem}})\n\nGet the kernels of the LR(1) item sets (items without lookahead).\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.merge_lr1_kernels-Tuple{Vector{Vector{ParsingItem}}, Dict{Int64, Dict{Symbol, Int64}}, Vector{Vector{ParsingItem}}}","page":"Parser","title":"JLRPG.JLRPG_Parser.merge_lr1_kernels","text":"merge_lr1_kernels(\n  lr1_item_sets::Vector{Vector{ParsingItem}},\n  lr1_gotos::Dict{Int, Dict{Symbol, Int}},\n  lr1_kernels::Vector{Vector{ParsingItem}}\n)\n\nMerge the LR(1) kernels that are equal.\n\nReturns a tuple of the merged item sets, gotos and mappings from the old item sets to the new ones.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.parser_grammar_symbols-Tuple{Parser}","page":"Parser","title":"JLRPG.JLRPG_Parser.parser_grammar_symbols","text":"parser_grammar_symbols(parser::Parser)\n\nConcatenate parser nonterminals and terminals into a single vector.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.read_parser_definition_file-Tuple{String}","page":"Parser","title":"JLRPG.JLRPG_Parser.read_parser_definition_file","text":"read_parser_definition_file(path::String)::Parser\n\nRead parser definition file and construct a Parser object.\n\nThe syntax for parser definition files follow the same syntax as GNU Bison definition files.\n\nDefinition file structure\n\nParser definition file consists of three sections:\n\nDefinitions section, where lexer tokens, types and parser options are defined.\nProductions section, where grammar productions are defined.\nCode section, where user code is defined.\n\nEach section is separated by a %% delimiter.\n\nDefinitions section\n\nDefinitions section consists of lexer tokens, types and parser options.\n\nLexer tokens\n\nEach lexer token that might be passed to parser during the parsing process must be defined in this section. To define a lexer token, use the following syntax:\n\n%token NAME \"ALIAS\"\n\nwhere NAME is the uppercased name of the token and ALIAS is a optional string literal, which may be used to refer to the token in the parser productions section.\n\nTypes\n\nEach nonterminal symbol may be assigned a type. To assign a type to a nonterminal, use the following syntax:\n\n%type <type> symbol\n\nwhere type is the type of the symbol and symbol is the lowercase name of the symbol. The type may be any valid Julia type, including user-defined types.\n\nIf a type is not assigned to a nonterminal, it is assumed to be Nothing.\n\nIf a type is assigned to a nonterminal, it is assumed that the user will return a value of that type from the action associated with the production. To return a value from the action, assign it to the $$ variable.\n\nParser options\n\nParser options may be used to configure the parser. Currently, the following options are available:\n\ntag: Rename the prefix of all objects generated in the parser. This includes all token definitions, special functions, etc.\nlexer_tag: Rename the prefix of all objects associated with the lexer that are used in the parser. This includes all token definitions, special functions, etc.\nparser_type: Specify the type of the parser. Currently, the following types are available:\nSLR\nLR\nLALR\n\nParser options are defined as follows:\n\n%option tag=\"TAG_NAME\"\n%option lexer_tag=\"LEXER_TAG_NAME\"\n%option SLR\n%option LR\n%option LALR\n\nwhere TAG_NAME is the new parser prefix, LEXER_TAG_NAME is the new prefix for lexer objects.\n\nRenaming the parser tag will also rename the default name of the generated parser file. For example if the tag is set to MyParser, the generated parser file will be named MyParser.jl.\n\nProductions section\n\nProductions section consists of grammar productions. Each production is defined as follows:\n\nlhs -> production :{ action }:\n\nwhere lhs is the left-hand side of the production, production is the right-hand side. Right-hand side might consist of terminals (uppercased symbols), nonterminals (lowercased symbols) or an %empty keyword, which represents an empty production. %empty should not be mixed with other symbols in a single production.\n\nThe action is an optional Julia code block, which is executed when the production is reduced. The action may return a value, which will be assigned to the left-hand side of the production. To return a value from the action, assign it to the $$ variable:\n\nlhs -> production :{ $$ = value }:\n\nIf a given left-hand side has multiple productions, they have to be defined below the first production using the following syntax:\n\nlhs -> production :{ action }:\n     | alt_production :{ action }:\n\nTo refer to the values of symbols in the right-hand side of the production, use the $<number> syntax, for example:\n\nlhs -> production :{ $$ = $1 + $3 }:\n\nwhere $n refers to the nth symbol in the right-hand side of the production.\n\nThe first production of the first nonterminal is considered as the starting production, unless a special flag is specified. Use %start flag to specify the starting production:\n\n%start lhs\n\nwhere lhs is the left-hand side of the starting production.\n\nCode section\n\nCode section consists of user code. It is copied to the output file as is, in the same order as it was defined in the definition file.\n\nAdditionally the user may define code blocks enclosed with %{ and %}, which will be also copied to the output file. Code blocks may be inserted in all of the sections, but they should not be intermixed with other definition file constructs (such as production definitions, flags, etc.).\n\nCommenting\n\nComments are defined using the #= and =# delimiters. Comments are single-line only. They should not be mixed with other definition file constructs.\n\nExamples\n\nFor valid parser definition files examples see the examples directory.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.replace_overloaded_functions_in_generated_parser-Tuple{String}","page":"Parser","title":"JLRPG.JLRPG_Parser.replace_overloaded_functions_in_generated_parser","text":"replace_overloaded_functions_in_generated_parser(\n  generated_parser::String\n)::String\n\nReplace overloaded functions in the generated parser code.\n\nScan the generated parser code for overloaded functions and replace the sections between # <<: ovearloaded_func start :>> and # <<: ovearloaded_func end :>> with a message that the function is overloaded.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.replace_special_tag_in_generated_parser-Tuple{String, String, String}","page":"Parser","title":"JLRPG.JLRPG_Parser.replace_special_tag_in_generated_parser","text":"replace_special_tag_in_generated_parser(\n  generated_parser::String,\n  parser_tag::String,\n  lexer_tag::String\n)::String\n\nReplace special lexer and parser tags in the generated parser code.\n\nThis function is used to replace the special prefixes present in all generated objects with the user-defined tags.\n\n\n\n\n\n","category":"method"},{"location":"api_parser/#JLRPG.JLRPG_Parser.replace_special_variables_in_generated_parser-Tuple{String}","page":"Parser","title":"JLRPG.JLRPG_Parser.replace_special_variables_in_generated_parser","text":"replace_special_variables_in_generated_parser(\n  generated_parser::String\n)::String\n\nReplace special variables in the generated parser code.\n\nCurrently only special variables are $$ and $n, which are replaced with __PAR__action_result and __PAR__symbols_slice[n] respectively.\n\n\n\n\n\n","category":"method"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#[wc](https://linux.die.net/man/1/wc)-like-program","page":"Examples","title":"wc-like program","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"This example shows how to generate a lexer for a simple wc-like program that counts the number of lines and words in a file.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"%{\nno_lines::Int = 0\nno_words::Int = 0\n%}\n\nINDENT      [ \\t]\nWHITESPACE  [ \\t\\n]\n\n%%\n\n{INDENT}+                           :{ }:\n\\n                                  :{ global no_lines += 1 }:\n[a-zA-Z0-9,.;_-]+                   :{ global no_words += 1 }:\n\n%%\n#= This is an overload of a special function, which is called =#\n#= when the lexer reaches the end of the input.               =#\nfunction __LEX__at_end()\n  println(\"========= OUTPUT =========\")\n  println(\"Number of lines: \", no_lines)\n  println(\"Number of words: \", no_words)\n  return 0\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To generate the lexer, run the following code:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using JLRPG\ngenerate_lexer(\"example.jlex\")","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"A file named __LEX__.jl will be created in the directory from which the command was run.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's test the lexer on the following input:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus id dui id ante laoreet tempor. Donec sodales orci sagittis dui porttitor, a pellentesque lectus tristique.\n\nPhasellus scelerisque cursus euismod. Sed ut odio ut libero tristique ullamcorper eget et est. Praesent dignissim eu ex at venenatis.\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam erat volutpat. Nam vel tortor eleifend, posuere quam quis, sollicitudin nisl.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Running the generated lexer with the above input will produce the following output:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"========= OUTPUT =========\nNumber of lines: 5\nNumber of words: 65","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Which is the same as the output of the wc -wl program:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"  5  65 test_input","category":"page"},{"location":"examples/#Generic-calculator","page":"Examples","title":"Generic calculator","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's create a simple calculator that can evaluate expressions like (1 + 2) * 3. The calculator will be able to handle addition, subtraction, multiplication and division. It will also be able to handle parenthesis.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Instead of hardcoding specific return types for the grammar nonterminals, we will define an abstract Operand type, which will have all the necessary arithemtic operations defined. To implement this type, the user has to overload basic arithmetic operators from the Julia language (Base.:+, Base.:-, etc.).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"First, let's create a lexer for our calculator:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"WHITESPACE (\\s|\\n)\nNUMBER     0|[1-9]+[0-9]*\n\n%%\n\n{WHITESPACE}+            :{ # Ignore }:\n{NUMBER}                 :{\n  val::Int = parse(Int, $$)\n  return Number(::Int=val)\n}:\n\"*\"                      :{ return Multiply() }:\n\"/\"                      :{ return Divide()   }:\n\"+\"                      :{ return Add()      }:\n\"-\"                      :{ return Subtract() }:\n\"(\"                      :{ return LParen()   }:\n\")\"                      :{ return RParen()   }:\n\n%%","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Then, let's define the Operand type:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Filename: operand.jl\nabstract type Operand end\n\nadd(a::Operand, b::Operand)::Operand = a + b\nsub(a::Operand, b::Operand)::Operand = a - b\nmul(a::Operand, b::Operand)::Operand = a * b\ndiv(a::Operand, b::Operand)::Operand = a / b","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"As an example, a simple implementation of the Galois field with parametric order p is given below:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Filename: galois_field.jl\n# Galois field calculator of order P\nstruct GF{P} <: Operand\n  value::Int\n  function GF{P}(value::Int) where {P}\n    return new(mod(value, P))\n  end\nend\n\n(Base.:+)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value + b.value)\n(Base.:-)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value - b.value)\n(Base.:*)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value * b.value)\n(Base.:/)(a::GF{P}, b::GF{P}) where P = GF{P}(a.value * invmod(b.value, P))","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Now, let's define the parser:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"%option LALR\n\n%{\ninclude(\"operand.jl\") #= Include the operand file =#\ninclude(\"galois_field.jl\") #= Include the Galois field file =#\n\nFIELD_PRIME::Int = 7\n%}\n\n#= Lexer token definitions =#\n%token MULTIPLY \"*\"\n%token DIVIDE \"/\"\n%token ADD \"+\"\n%token SUBTRACT \"-\"\n%token LPAREN \"(\"\n%token RPAREN \")\"\n%token NUMBER\n\n#= Returned types =#\n%type <GF{FIELD_PRIME}> e\n%type <GF{FIELD_PRIME}> t\n%type <GF{FIELD_PRIME}> f\n\n%%\n#= Productions =#\n%start s\ns -> e         :{ println($1)                    }:\ne -> e \"+\" t   :{ $$ = add($1, $3)               }:\n   | e \"-\" t   :{ $$ = sub($1, $3)               }:\n   | t         :{ $$ = $1                        }:\nt -> t \"*\" f   :{ $$ = mul($1, $3)               }:\n   | t \"/\" f   :{ $$ = div($1, $3)               }:\n   | f         :{ $$ = $1                        }:\nf -> NUMBER    :{ $$ = GF{FIELD_PRIME}($1.value) }:\n   | \"(\" e \")\" :{ $$ = $2                        }:\n\n%%","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This grammar ensures that the order of operations is preserved. Currently there is no way to define the precedence of terminals in the grammar file, so the user has to define the precedence manually in the grammar productions.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To generate the parser, run the following code:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using JLRPG\ngenerate_parser(\"example.jpar\")","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"A file named __PAR__.jl will be created in the directory from which the command was run.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's test the parser on the following input:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(2 + 11) * 6","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This should equal 1, since 78 = 1 (mod 7). Running the generated parser with the above input will produce the following output:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"GaloisField{order=7}(1)","category":"page"},{"location":"examples/#Changing-the-program-arguments-of-the-generated-parser","page":"Examples","title":"Changing the program arguments of the generated parser","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Currently the order of the Galois field calculator is hardcoded in the parser file. To change it, the user has to modify the FIELD_PRIME constant in the parser file and regenerate the parser.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To avoid this, the __PAR__main() function can be overloaded in the definition file. This function is called when the generated parser is run.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's modify the previous example to use below functions:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"function __PAR__usage()\n  println(\"Usage: $(PROGRAM_FILE) [source file] [order]\")\nend\n\nfunction __PAR__main()\n  if length(ARGS) != 2\n    return __PAR__usage()\n  elseif ARGS[1] == \"-h\" || ARGS[1] == \"--help\"\n    return __PAR__usage()\n  elseif !isfile(ARGS[1])\n    error(\"File \\\"$(ARGS[1])\\\" does not exist\")\n  else\n    try\n      global FIELD_PRIME = parse(Int, ARGS[2])\n    catch e\n      error(\"Invalid order argument, must be an integer, got: \\\"$(ARGS[2])\\\"\")\n    end\n\n    txt = \"\"\n    open(ARGS[1]) do file\n      txt = read(file, String)\n      __LEX__bind_cursor(Cursor(txt; source=ARGS[1]))\n    end\n\n    tokens = nothing\n    try\n      tokens = __LEX__tokenize()\n    catch e\n      e = ErrorException(replace(e.msg, r\"\\n       \" => \"\\n\"))\n      @error \"Error while tokenizing input\" exception=(e, catch_backtrace())\n      exit(1)\n    end\n\n    try\n      __PAR__simulate(tokens)\n    catch e\n      if e isa ErrorException\n        e = ErrorException(replace(e.msg, r\"\\n       \" => \"\\n\"))\n        @error \"Error while parsing tokens\" exception=(e, catch_backtrace())\n        exit(1)\n      end\n      @error \"Error while parsing tokens\" exception=(e, catch_backtrace())\n    end\n  end\n\n  return __PAR__at_end()\nend","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Now an additional argument has to be provided to the parser, which is the order of the Galois field. Let's test the parser on the following input and order 21:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(2 + 11) * 6","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This should equal 15, since 78 = 15 (mod 21).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Running the generated parser with the above input and order will produce the following output:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"GaloisField{order=21}(15)","category":"page"},{"location":"examples/#Simple-AST-for-the-calculator","page":"Examples","title":"Simple AST for the calculator","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"The most powerful feature of each LR parser is the ability to create an abstract syntax tree (AST) for the input. This example shows how to create a simple AST for the calculator from the previous example.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's define basic AST node types and a function that will evaluate the provided arithmetic operations tree:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Filename: ast.jl\nabstract type Node end\n\nstruct NumNode <: Node\n  value::Operand\nend\n\nstruct AddNode <: Node\n  left::Node\n  right::Node\nend\n\nstruct SubNode <: Node\n  left::Node\n  right::Node\nend\n\nstruct MulNode <: Node\n  left::Node\n  right::Node\nend\n\nstruct DivNode <: Node\n  left::Node\n  right::Node\nend\n\neval(n::Num)::Operand = n.value\neval(n::Add)::Operand = add(eval(n.left), eval(n.right))\neval(n::Sub)::Operand = sub(eval(n.left), eval(n.right))\neval(n::Mul)::Operand = mul(eval(n.left), eval(n.right))\neval(n::Div)::Operand = div(eval(n.left), eval(n.right))","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The abstract Node type will be used as a return type for the grammar nonterminals. All operators contain references to other Node objects, which allows us to create a tree structure.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Now, let's modify the parser from the previous example to return Node objects:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"%option LALR\n\n%{\ninclude(\"operand.jl\") #= Include the operand file =#\ninclude(\"galois_field.jl\") #= Include the Galois field file =#\ninclude(\"ast.jl\") #= Include the AST file =#\n\nFIELD_PRIME::Int = 7\n%}\n\n#= Lexer token definitions =#\n%token MULTIPLY \"*\"\n%token DIVIDE \"/\"\n%token ADD \"+\"\n%token SUBTRACT \"-\"\n%token LPAREN \"(\"\n%token RPAREN \")\"\n%token NUMBER\n\n#= Returned types =#\n%type <Node> e\n%type <Node> t\n%type <Node> f\n\n%%\n#= Productions =#\n%start s\ns -> e         :{ println($1); println(eval($1))          }:\ne -> e \"+\" t   :{ $$ = AddNode($1, $3)                    }:\n   | e \"-\" t   :{ $$ = SubNode($1, $3)                    }:\n   | t         :{ $$ = $1                                 }:\nt -> t \"*\" f   :{ $$ = MulNode($1, $3)                    }:\n   | t \"/\" f   :{ $$ = DivNode($1, $3)                    }:\n   | f         :{ $$ = $1                                 }:\nf -> NUMBER    :{ $$ = NumNode(GF{FIELD_PRIME}($1.value)) }:\n   | \"(\" e \")\" :{ $$ = $2                                 }:\n\n%%","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"As you can see, the GF{P} type will still be used, but now a tree-like structure will be created from the input. To see what tree has been created for the given input, an additional print statement has been added to the s production.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To generate the parser, run the following code:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using JLRPG\ngenerate_parser(\"example.jpar\")","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"For the same input as in the previous example, the following output will be produced:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"MulExpr(AddExpr(Num(GaloisField{order=7}(2)), Num(GaloisField{order=7}(4))), Num(GaloisField{order=7}(6)))\nGaloisField{order=7}(1)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This is a proper way of creating an AST for this example, since the order of operations and parenthesis are preserved.","category":"page"},{"location":"api_simplelexer/#SimpleLexer-API-reference","page":"SimpleLexer","title":"SimpleLexer API reference","text":"","category":"section"},{"location":"api_simplelexer/","page":"SimpleLexer","title":"SimpleLexer","text":"Modules = [JLRPG.JLRPG_SimpleLexer]\nOrder   = [:type, :function]","category":"page"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.ArgumentType","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.ArgumentType","text":"All possible types of arguments passed to a lexer token\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.Lexer","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.Lexer","text":"Lexer definition.\n\nDefines a lexer with a set of actions, aliases, code_blocks and options. Created by read_lexer_definition_file function.\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.LexerAction","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.LexerAction","text":"Lexer action definition.\n\nDefines a lexer action with a pattern and a body:\n\npattern :{ body }:\n\nAction body is a string of Julia code that is executed when a pattern is matched.\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.LexerOptions","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.LexerOptions","text":"Lexer options definition.\n\nCurrently only tag option is supported. It defines the tag that will be preprended to all objects generated in the lexer file.\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.LexerToken","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.LexerToken","text":"Lexer token type.\n\nBy default, all LexerTokens will inherit this type and have some default members generated by the lexer generator.\n\nExample of a generated token\n\nstruct Num <: LexerToken\n    symbol::Symbol   # This is the name of the token\n    values::Dict     # Dict of all values passed during token creation\n                     # Those values may be typed, but it is not required\n                     # You can access those values by using simple member access notation (token.value)\n    file_pos::String # File position of the token\n    ???              # Anything else that may be added in the future\nend\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.LexerTokenDefinition","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.LexerTokenDefinition","text":"Lexer token definition.\n\nContains a name and a set of arguments that will be passed to the token constructor inside of generated lexer file.\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.PatternPart","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.PatternPart","text":"Possible parts of a pattern in a lexer action.\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.RegexAlias","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.RegexAlias","text":"Regex alias definition.\n\nDefines a regex alias with a name and a PCRE2-compliant regex pattern:\n\nname pattern\n\nRegex aliases are used to simplify lexer definitions. They are expanded during lexer generation.\n\n\n\n\n\n","category":"type"},{"location":"api_simplelexer/#Base.getproperty-Tuple{LexerToken, Symbol}","page":"SimpleLexer","title":"Base.getproperty","text":"Base.getproperty(token::LexerToken, name::Symbol)\n\nSupport for member access notation (token.value)\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.expand_regex_aliases_in_actions-Tuple{Vector{LexerAction}, Vector{RegexAlias}}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.expand_regex_aliases_in_actions","text":"expand_regex_aliases_in_actions(\n  actions::Vector{LexerAction},\n  expanded_aliases::Vector{RegexAlias}\n)::Vector{LexerAction}\n\nExpand lexer regex aliases inside of the patterns of actions.\n\nAliases provided as expanded_aliases should contain previously expanded aliases. Literal strings enclosed in double quotes are escaped using \\Q and \\E sequences.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.expand_regex_aliases_in_aliases-Tuple{Vector{RegexAlias}}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.expand_regex_aliases_in_aliases","text":"expand_regex_aliases_in_aliases(aliases::Vector{RegexAlias})::Vector{RegexAlias}\n\nExpand lexer regex aliases inside the patterns of other aliases.\n\nAliases have to be defined before they are referenced.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.expand_regex_aliases_in_lexer-Tuple{Lexer}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.expand_regex_aliases_in_lexer","text":"expand_regex_aliases_in_lexer(lexer::Lexer)::Lexer\n\nExpand aliases and actions in lexer into proper regexes.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.fill_lexer_template-Tuple{Vector{LexerTokenDefinition}, Vector{String}, Vector{LexerAction}}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.fill_lexer_template","text":"fill_lexer_template(\n  tokens::Vector{LexerTokenDefinition},\n  codeblocks::Vector{String},\n  actions::Vector{LexerAction}\n)::String\n\nFill the lexer mustache template with the given tokens, codeblocks and actions.\n\nThis function is used internally by generate_lexer function.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.generate_lexer","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.generate_lexer","text":"generate_lexer(definition_path::String, output_path::String=\"__LEX__.jl\")\n\nGenerate a lexer source file from a lexer definition file.\n\nThe lexer definition file should follow the syntax described in both read_lexer_definition_file and SimpleLexer module documentation.\n\nBy default parsers assume that there is a lexer file named __LEX__.jl in the same directory as the parser file. The user may specify a different path by passing output_path argument. If another path is specified, it is required that the user manually include the generated lexer file in the parser definition file.\n\n\n\n\n\n","category":"function"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.read_lexer_definition_file-Tuple{String}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.read_lexer_definition_file","text":"read_lexer_definition_file(path::String)::Lexer\n\nRead lexer definition file from path and construct a Lexer object.\n\nThe syntax for lexer definition files follow the same syntax as Flex definition files.\n\nDefinition file structure\n\nLexer definition file consists of three sections:\n\nDefinitions section, where regex aliases and lexer options are defined.\nActions section, where lexer actions are defined.\nCode section, where user code is defined.\n\nEach section is separated by a %% delimiter.\n\nDefinitions section\n\nDefinitions section consists of regex aliases and lexer options. Regexes should conform to the PCRE syntax, since Julia uses PCRE regexes.\n\nRegex aliases\n\nRegex aliases are defined as follows:\n\nALIAS_NAME REGEX\n\nwhere ALIAS_NAME is a name of the alias and REGEX is a regex pattern.\n\nRegex aliases can be referenced in other regexes by using {ALIAS_NAME} syntax. If an alias is referenced before it is defined, an error will be thrown.\n\nLexer options\n\nCurrently there's only one lexer option available: tag. This option allows renaming of the prefix of all objects generated in the lexer. This includes all token definitions, special functions, etc.\n\nThe tag option is defined as follows:\n\n%option tag=\"TAG_NAME\"\n\nwhere TAG_NAME is the new prefix.\n\nRenaming the lexer tag will also rename the default name of the generated lexer file. For example, if the tag is set to MyLexer, the generated lexer file will be named MyLexer.jl. Keep in mind, that a generated parser requires __LEX__.jl file to be present in the same directory. If no such file is found, it is required that the user includes it by themselves using in a code block/section.\n\nActions section\n\nActions section consists of lexer actions. Each lexer action is defined as follows:\n\nPATTERN :{ ACTION_BODY }:\n\nwhere PATTERN is a regex pattern and ACTION_BODY is a Julia code block.\n\nThe PATTERN is matched against the input text. If the match is successful, the ACTION_BODY is executed. The ACTION_BODY should return a token object, but it is not required.\n\nAction patterns\n\nAction patterns are constructed using one or many pattern parts: regexes, aliases or literal strings. Patterns should not be separated by whitespace, since it is treated as a literal whitespace character. Literal strings are strings enclosed in double quotes (\"). They are treated as a sequence of characters, not as a regex. Regexes are defined using the PCRE syntax.\n\nFor example:\n\n\"hello\"{ALIAS_NAME}[0-9]+\n\nis a valid pattern definition, which will be later converted to a single regex.\n\nAction tokens\n\nEach action body may return a token object using the return keyword. There is no need to predefine token types, since they are generated automatically by retrieve_tokens_from_actions function.\n\nTokens are defined as follows:\n\nreturn TOKEN_NAME(ARGUMENTS)\n\nwhere TOKEN_NAME is a name of the token and ARGUMENTS is a list of arguments. Arguments may be named and typed, but it is not required. See: retrieve_tokens_from_actions for more information.\n\nCode section\n\nCode section consists of user code. It is copied to the output file as is, in the same order as it was defined in the definition file.\n\nAdditionally the user may define code blocks enclosed with %{ and %}, which will be also copied to the output file. Code blocks may be inserted in all of the sections, but they should not be intermixed with other definition file constructs (such as action patterns, action bodies, etc.).\n\nCommenting\n\nComments are defined using the #= and =# delimiters. Comments are single-line only. They should not be mixed with other definition file constructs.\n\nExample\n\nFor valid lexer definition files examples see the examples directory.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.replace_overloaded_functions_in_generated_lexer-Tuple{String}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.replace_overloaded_functions_in_generated_lexer","text":"replace_overloaded_functions_in_generated_lexer(\n  generated_lexer::String\n)::String\n\nReplace overloaded functions in the generated lexer code.\n\nScan the generated lexer code for overloaded functions and replace the sections between # <<: ovearloaded_func start :>> and # <<: ovearloaded_func end :>> with a message that the function is overloaded.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.replace_special_tag_in_generated_lexer-Tuple{String, String}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.replace_special_tag_in_generated_lexer","text":"replace_special_tag_in_generated_lexer(\n  generated_lexer::String,\n  tag::String\n)::String\n\nReplace special tag in the generated lexer code.\n\nThis function is used to replace the special prefix present in all generated objects with the user-defined tag.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.replace_special_variables_in_generated_lexer-Tuple{String}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.replace_special_variables_in_generated_lexer","text":"replace_special_variables_in_generated_lexer(\n  generated_lexer::String\n)::String\n\nReplace special variables in the generated lexer code.\n\nCurrently the only special variable is $$, which is replaced with __LEX__current_match().\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.replace_token_args_in_actions-Tuple{Vector{LexerAction}, Dict{Symbol, Vector}}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.replace_token_args_in_actions","text":"replace_token_args_in_actions(\n  lexer::Lexer,\n  defined_tokens::Vector{LexerTokenDefinition}\n)::Lexer\n\nConvert token definitions from lexer definition file to conform to the code generation template.\n\nThis function does two things:\n\nPrepends a special lexer tag to each token name. This is done to avoid name collisions with user-defined functions.\nReplaces arguments passed to returned tokens with a list of keyword arguments. Argument names should be defined in the defined_tokens vector.\n\nFor example return Number(1) will become return __LEX__Number(;value=1).\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.retrieve_tokens_from_actions-Tuple{Vector{LexerAction}}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.retrieve_tokens_from_actions","text":"retrieve_tokens_from_actions(actions::Vector{LexerAction})::Vector{LexerTokenDefinition}\n\nScan lexer actions for returned tokens and their arguments.\n\nEach lexer action may return some sort of token, which is later passed to the parser. Tokens may contain additional parameters of any type interpretable by Julia. All parameters may be named and typed, but it is not required.\n\nArgument naming rules:\n\nIf a token has only one parameter and it is not named, it will be named as value.\nIf a token has more than one parameter and they are not named, they will be named as value1, value2, etc.\nIf a custom name is specified, it will be used instead of the default name.\n\nArgument typing rules:\n\nIf no type is specified, the value will be a String.\nOtherwise, the value will be treated as a value of the specified type. The user should make sure that a proper value for this type is passed.\n\nExamples:\n\n{NUM} { return Num(5) } A type for the first argument is not specified, so it will be treated as a String\n{NUM} { return Num(::Int=5) } Num has value of type Int\n{ID}  { return ID(\"hello\", \"world\", ::Int=4)} ID has 3 arguments, all of which will be retrieveable by using token.value1, token.value2, token.value3\n{ID}  { return ID(first::String=\"hello\", second::String=\"world\", num::Int=4)} ID has 3 arguments, all of which will be retrieveable by using token.first, token.second, token.num\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.token_file_pos-Tuple{LexerToken}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.token_file_pos","text":"token_file_pos(token::LexerToken)::String\n\nReturn the file position of the token.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.token_symbol-Tuple{LexerToken}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.token_symbol","text":"token_symbol(token::LexerToken)::Symbol\n\nReturn the symbol associated with the token.\n\n\n\n\n\n","category":"method"},{"location":"api_simplelexer/#JLRPG.JLRPG_SimpleLexer.token_values-Tuple{LexerToken}","page":"SimpleLexer","title":"JLRPG.JLRPG_SimpleLexer.token_values","text":"token_values(token::LexerToken)::Dict\n\nReturn all values passed during token creation.\n\n\n\n\n\n","category":"method"},{"location":"#JLRPG.jl","page":"Getting started","title":"JLRPG.jl","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Lexer & LR parser generator for Julia.","category":"page"},{"location":"#Installation","page":"Getting started","title":"Installation","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"JLRPG.jl can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"pkg> add https://github.com/Flowyh/JLRPG.jl","category":"page"},{"location":"#Features","page":"Getting started","title":"Features","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Generating simplified lexers using Flex-like syntax.\nGenerating parsers using Bison-like syntax.\nSupport for SLR, LR(1) and LALR(1) grammars.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The documentation for simplified lexer definition files can be found at SimpleLexer definition files page.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"The documentation for parser definition files can be found at Parser definition files page.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Some examples of valid lexer and parser definition files can be found at Examples.","category":"page"},{"location":"#Quick-start","page":"Getting started","title":"Quick start","text":"","category":"section"},{"location":"#Lexer","page":"Getting started","title":"Lexer","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"The following example shows how to generate a lexer for a simple language that recognizes + * operators, parenthesis and numbers.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"WHITESPACE (\\s|\\n)\nNUMBER     0|[1-9]+[0-9]*\n\n%%\n\n{WHITESPACE}+            :{ # Ignore }:\n{NUMBER}                 :{\n  val::Int = parse(Int, $$)\n  return Number(::Int=val)\n}:\n\"*\"                      :{ return Multiply() }:\n\"+\"                      :{ return Add()      }:\n\"(\"                      :{ return LParen()   }:\n\")\"                      :{ return RParen()   }:\n\n%%","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"To generate the lexer, run the following code:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using JLRPG\ngenerate_lexer(\"example.jlex\")","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"A generated lexer file __LEX__.jl will be created in the directory from which the command was run. To test if the lexer works as expected you can run it directly using Julia interpreter:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"$ julia __LEX__.jl","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"the program will wait for any input (until Ctrl+D is pressed) and tokenize it.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"In this example nothing will be printed to the standard output. You can enable debug mode by running the program with JULIA_DEBUG=Main variable enabled, to see what is happening behind the scenes:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"$ JULIA_DEBUG=Main julia __LEX__.jl","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Alternitavely, you can pass an input file to the lexer:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"$ julia __LEX__.jl example.txt","category":"page"},{"location":"#Parser","page":"Getting started","title":"Parser","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"The following example shows how to generate a LALR parser for a simple integer arithmetic language.","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"%option LALR\n\n#= Lexer token definitions =#\n%token MULTIPLY \"*\"\n%token ADD \"+\"\n%token LPAREN \"(\"\n%token RPAREN \")\"\n%token NUMBER\n\n#= Returned types =#\n%type <Int> e\n%type <Int> t\n%type <Int> f\n\n%%\n#= Productions =#\n%start s\ns -> e         :{ println($1)   }:\ne -> e \"+\" t   :{ $$ = $1 + $3  }:\n   | t         :{ $$ = $1       }:\nt -> t \"*\" f   :{ $$ = $1 * $3  }:\n   | f         :{ $$ = $1       }:\nf -> NUMBER    :{ $$ = $1.value }:\n   | \"(\" e \")\" :{ $$ = $2       }:\n\n%%","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"To generate the parser, run the following command:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using JLRPG\ngenerate_parser(\"example.jpar\")","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"A generated parser file __PAR__.jl will be created in the directory from which the command was run. To test if the parser works as expected you can run it directly using Julia interpreter, but this time you need to pass an input file to the parser:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"$ julia __PAR__.jl example.txt","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"In this example the parser will tokenize the file, analyze it's syntax and print the result to the standard output. If any syntax error is found, the parser will print an error message and exit.","category":"page"},{"location":"#License","page":"Getting started","title":"License","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"This project is licensed under the MIT License - see the LICENSE file for details.","category":"page"},{"location":"lexer/#SimpleLexer-definition-files","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"The first step of creating a proper parser is to define a lexer. JLRPG.jl supports generation of simplified lexer files, which rely on Julia's regex engine (PCRE2 standard).","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Customarily, lexer definition files have .jlex extension.","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Lexer definition files consist of three sections:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"definitions - in this section regex aliases and lexer options should be defined.\nactions - lexer actions are defined here.\ncode - user defined code that will be copied into the generated lexer file might be placed here.","category":"page"},{"location":"lexer/#Definitions","page":"SimpleLexer definition files","title":"Definitions","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Definitions section is optional. It consists of regex aliases and lexer options.","category":"page"},{"location":"lexer/#Regex-aliases","page":"SimpleLexer definition files","title":"Regex aliases","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Regex aliases are defined in the following way:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"ALIAS_NAME REGEX","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"where ALIAS_NAME is the name of the alias and REGEX is the PCRE2 conformant regex that will be aliased. Regex aliases can be used in lexer actions or other regex aliases.","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"To use a regex alias the following syntax should be used:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"{ALIAS_NAME}","category":"page"},{"location":"lexer/#%option","page":"SimpleLexer definition files","title":"%option","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Lexer options are defined in the following way:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"%option OPTION_NAME\n%option KEYWORD_OPTION_NAME=VALUE","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"where OPTION_NAME or KEYWORD_OPTION_NAME is the name of the option and VALUE is the value of the option. Lexer options can be used to change the behaviour of the lexer.","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Currently there's only one lexer option available:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"%option tag=TAG_NAME","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"It allows to change the prefix of all generated object names. By default it is set to __LEX__.","category":"page"},{"location":"lexer/#Actions","page":"SimpleLexer definition files","title":"Actions","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Actions section is required. It consists of lexer actions.","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Lexer actions are defined in the following way:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"PATTERN :{ ACTION }:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"where PATTERN may consist of three different parts:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"normal regex pattern\nregex aliases\nliteral strings enclosed in double quotes, they are treated as normal characters (useful for matching special regex characters, like *, +, ?, etc.)","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"ACTION is a Julia code that will be executed when the pattern is matched. It may consist of multiple lines of code, but it must be enclosed in special delimiters: :{ and }:.","category":"page"},{"location":"lexer/#Returning-tokens-from-lexer-actions","page":"SimpleLexer definition files","title":"Returning tokens from lexer actions","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Lexer actions may return a token, which will be later passed to the parser. To return a token, the following syntax should be used:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"return Token(parameters...)","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"where Token is the name of the token type and parameters... are the parameters that will be passed to the token constructor. Parameters may be named and typed, but it is not required.","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"If a token argument is not typed, it is assumed to be of type String.","category":"page"},{"location":"lexer/#Token-parameters-naming-rules","page":"SimpleLexer definition files","title":"Token parameters naming rules","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Parameter naming rules are as follows:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"If a token has only one argument and it is not named, then it's name is value.\nIf a token has more than one argument and they are not named, the their name are value1, value2, ..., valueN, where N is the position of the argument.\nIf an argument is named, then it is accessible by it's name.","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"There's no need to define a tokens type before using it in a lexer action. All actions are scanned during the definition file analysis and all tokens types are automatically generated.","category":"page"},{"location":"lexer/#Referencing-the-current-matched-string","page":"SimpleLexer definition files","title":"Referencing the current matched string","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"To reference the current matched string, double dollar sign syntax should be used, for example:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"{NUMBER}                 :{\n  val::Int = parse(Int, $$)\n  return Number(::Int=val)\n}:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"In this example, the currently matched number text is parsed into an integer and then passed to the Number token constructor.","category":"page"},{"location":"lexer/#Code","page":"SimpleLexer definition files","title":"Code","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Code section is optional. It consists of user defined code that will be pasted into the generated lexer file.","category":"page"},{"location":"lexer/#Additional-code-blocks","page":"SimpleLexer definition files","title":"Additional code blocks","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Additionally, the user can insert additional code blocks into the definition file using the following delimiters:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"%{\n...\n%}","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Be mindful that the code blocks should not be intermixed with other definition file constructs (e.g. lexer options, regex aliases, etc.).","category":"page"},{"location":"lexer/#Comments","page":"SimpleLexer definition files","title":"Comments","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Comments in lexer definition files are single-line and are enclosed by special delimiters:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"#= ... =#","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Comments should not be mixed with other definition file constructs (e.g. lexer options, regex aliases, etc.).","category":"page"},{"location":"lexer/#Special-function-overloading","page":"SimpleLexer definition files","title":"Special function overloading","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"Some special functions in the generated lexer file can be overloaded by the user. The following functions can be overloaded:","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"__LEX__at_end() - this function is run after the lexer has finished tokenizing the input. By default it returns false as an indicator of success.\n__LEX__main() - this function is run when the lexer is run directly from the command line. By default it either reads the input from the standard input or from the file specified as the first command line argument and then tokenizes it.\n__LEX__usage() - used to print the helper usage message when the lexer is run incorrectly from the command line. By default it prints the following message:\nUsage: $(PROGRAM_FILE) [source file]","category":"page"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"To overload a function, just define it in the code section/block of the lexer definition file.","category":"page"},{"location":"lexer/#Valid-lexer-definition-files-examples","page":"SimpleLexer definition files","title":"Valid lexer definition files examples","text":"","category":"section"},{"location":"lexer/","page":"SimpleLexer definition files","title":"SimpleLexer definition files","text":"See Examples for valid lexer definition files examples.","category":"page"},{"location":"parser/#Parser-definition-files","page":"Parser definition files","title":"Parser definition files","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"The main purpose of this package is to generate LR parsers from Bison-like parser definition files.","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Customarily, lexer definition files have .jlex extension.","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"The parser definition files consist of three sections:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"definitions - in this section tokens, nonterminal types and options should be defined.\nproductions - grammar rules are defined here.\ncode - user defined code that will be copied into the generated parser file might be placed here.","category":"page"},{"location":"parser/#Definitions","page":"Parser definition files","title":"Definitions","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"In the definition section tokens are the only parser elements that are required to be defined. They inform the parser about what tokens may come from the lexer output.","category":"page"},{"location":"parser/#%token","page":"Parser definition files","title":"%token","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Lexer tokens are defined in the following way:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"%token TOKEN_NAME \"alias\"","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"where TOKEN_NAME is the uppercased name of the token, and \"alias\" is the optional alias of the token. The alias is used to refer to the token in the parser productions. If the alias is not specified, the token name shall be used instead.","category":"page"},{"location":"parser/#%type","page":"Parser definition files","title":"%type","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Nonterminal types are defined in the following way:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"%type <Type> nonterminal_name","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"where <Type> is the type of the nonterminal and nonterminal_name is the lowercased name of the nonterminal. The type of the nonterminal may be any valid Julia type, including user-defined types. By default, if not specified, the type of the nonterminal is set to Nothing.","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"All nonterminal names in the definition file should be lowercase, and all terminal names should be uppercase. This is required to distinguish between terminals and nonterminals in the parser productions.","category":"page"},{"location":"parser/#%option","page":"Parser definition files","title":"%option","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Parser options are defined in the following way:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"%option OPTION_NAME\n%option KEYWORD_OPTION_NAME=VALUE","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"where OPTION_NAME or KEYWORD_OPTION_NAME is the name of the option and VALUE is the value of the option. Parser options can be used to change the behaviour of the parser.","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Currently these parser options are available:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"#= Parser type =#\n%option SLR\n%option LR\n%option LALR\n\n#= Tag =#\n%option tag=TAG_NAME\n%option lexer_tag=LEXER_TAG_NAME","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"First three options are used to specify the type of the parser. By default the parser type is set to SLR.","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"The last two options are used to change the prefix of all generated object names. By default it is set to __PAR__ for parser files and __LEX__ for lexer files. To change the prefix of the parser object names, use the tag option. If a lexer with a custom prefix is used, the lexer_tag option should be used to specify the prefix of the lexer object names.","category":"page"},{"location":"parser/#Productions","page":"Parser definition files","title":"Productions","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"In the productions section grammar rules are defined. The grammar rules are defined in the following way:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"lhs -> rhs :{ ACTION }:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"where lhs is the name of the nonterminal on the left-hand side of the rule, rhs is the sequence of terminals and nonterminals on the right-hand side of the rule, and ACTION is the action that will be executed when the rule is reduced. The action is optional.","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"If a certain nonterminal has more than one production defined, the alternative production should be defined right below the first one, using the | symbol:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"lhs -> rhs     :{ ACTION     }:\n     | alt_rhs :{ ALT_ACTION }:","category":"page"},{"location":"parser/#Special-production-variables","page":"Parser definition files","title":"Special production variables","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"The main task of the parser is to create some sort of structurized representation of the input. To do that, the parser needs to assign variables to the lhs nonterminals. Just like in Bison, the variables are assigned using the $ symbol:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"lhs -> rhs :{ $$ = $1, ... $n }:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"where $n is the n-th element of the rhs sequence. The $$ symbol can also be used to refer to the lhs nonterminal in the action. The type assigned to the $$ should be the same as the type of the lhs nonterminal.","category":"page"},{"location":"parser/#%start","page":"Parser definition files","title":"%start","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"The first lhs of the first production is treated as the start symbol of the grammar. To change the start symbol, use the %start option:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"%start START_SYMBOL","category":"page"},{"location":"parser/#Code","page":"Parser definition files","title":"Code","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"In the code section user-defined code that will be copied into the generated parser file might be placed. This section is optional.","category":"page"},{"location":"parser/#Additional-code-blocks","page":"Parser definition files","title":"Additional code blocks","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Additionally, the user can insert additional code blocks into the definition file using the following delimiters:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"%{\n...\n%}","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Be mindful that the code blocks should not be intermixed with other definition file constructs (e.g. parser options, productions, etc.).","category":"page"},{"location":"parser/#Comments","page":"Parser definition files","title":"Comments","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Comments in parser definition files are single-line and are enclosed by special delimiters:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"#= ... =#","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Comments should not be mixed with other definition file constructs (e.g. parser options, productions, etc.).","category":"page"},{"location":"parser/#Special-function-overloading","page":"Parser definition files","title":"Special function overloading","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"Some special functions in the generated parser file can be overloaded by the user. The following functions can be overloaded:","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"__PAR__at_end() - this function is run after the parser has finished parsing the input. By default it returns false as an indicator of success.\n__PAR__main() - this function is run when the parser is run directly from the command line. By default it either reads the input from the file specified as the first command line argument, tokenizes it using the provided lexer and then proceeds to parse it.\n__PAR__usage() - used to print the helper usage message when the parser is run incorrectly from the command line. By default it prints the following message:\nUsage: $(PROGRAM_FILE) [source file]","category":"page"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"To overload a function, just define it in the code section/block of the parser definition file.","category":"page"},{"location":"parser/#Valid-parser-definition-files-examples","page":"Parser definition files","title":"Valid parser definition files examples","text":"","category":"section"},{"location":"parser/","page":"Parser definition files","title":"Parser definition files","text":"See Examples for valid parser definition files examples.","category":"page"}]
}
